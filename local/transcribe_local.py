#!/usr/bin/env python3
"""
Local Whisper Transcription Script

This script uses OpenAI's Whisper model installed locally to transcribe audio files.
It supports various audio formats and Whisper model sizes.

Usage:
    python transcribe_local.py input.mp3 --model medium --language en
"""

import argparse
import os
import sys
import time
from pathlib import Path
from typing import Optional

try:
    import whisper
except ImportError:
    print("‚ùå OpenAI Whisper not found. Install it with:")
    print("   pip install -U openai-whisper")
    sys.exit(1)


def transcribe_file(
    audio_path: str,
    model_name: str = "base",
    language: Optional[str] = None,
    task: str = "transcribe",
    output_dir: Optional[str] = None,
    verbose: bool = True,
) -> dict:
    """
    Transcribe an audio file using Whisper.

    Args:
        audio_path: Path to the audio file
        model_name: Whisper model size (tiny, base, small, medium, large)
        language: Language code (e.g., 'en', 'es', 'fr'). Auto-detect if None
        task: Either 'transcribe' or 'translate'
        output_dir: Directory to save output files. Same as input if None
        verbose: Print progress information

    Returns:
        Dictionary containing transcription results
    """
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    if verbose:
        print(f"üéµ Loading audio file: {audio_path}")
        print(f"ü§ñ Loading Whisper model: {model_name}")

    # Load the model
    start_time = time.time()
    model = whisper.load_model(model_name)
    load_time = time.time() - start_time

    if verbose:
        print(f"‚è±Ô∏è  Model loaded in {load_time:.2f} seconds")
        print(f"üéØ Starting {task}...")

    # Perform transcription
    start_time = time.time()
    result = model.transcribe(audio_path, language=language, task=task, verbose=verbose)
    transcribe_time = time.time() - start_time

    if verbose:
        print(f"‚úÖ {task.capitalize()} completed in {transcribe_time:.2f} seconds")

    # Save output files
    if output_dir is None:
        output_dir = os.path.dirname(audio_path)

    audio_basename = Path(audio_path).stem
    output_base = os.path.join(output_dir, audio_basename)

    # Save as text file
    txt_path = f"{output_base}.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(result["text"])

    # Save as SRT (subtitle) file
    srt_path = f"{output_base}.srt"
    write_srt(result, srt_path)

    # Save as VTT (WebVTT) file
    vtt_path = f"{output_base}.vtt"
    write_vtt(result, vtt_path)

    if verbose:
        print(f"üìÑ Text saved to: {txt_path}")
        print(f"üì∫ SRT subtitles saved to: {srt_path}")
        print(f"üåê VTT subtitles saved to: {vtt_path}")

    return result


def write_srt(result: dict, output_path: str):
    """Write transcription result as SRT subtitle file."""
    with open(output_path, "w", encoding="utf-8") as f:
        for i, segment in enumerate(result["segments"], 1):
            start_time = format_timestamp(segment["start"])
            end_time = format_timestamp(segment["end"])
            text = segment["text"].strip()

            f.write(f"{i}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{text}\n\n")


def write_vtt(result: dict, output_path: str):
    """Write transcription result as WebVTT subtitle file."""
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("WEBVTT\n\n")

        for segment in result["segments"]:
            start_time = format_timestamp(segment["start"], vtt_format=True)
            end_time = format_timestamp(segment["end"], vtt_format=True)
            text = segment["text"].strip()

            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{text}\n\n")


def format_timestamp(seconds: float, vtt_format: bool = False) -> str:
    """Format seconds as timestamp string."""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int((seconds % 1) * 1000)

    if vtt_format:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}.{milliseconds:03d}"
    else:
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


def main():
    parser = argparse.ArgumentParser(
        description="Transcribe audio files using OpenAI Whisper",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python transcribe_local.py audio.mp3
  python transcribe_local.py video.mp4 --model medium --language en
  python transcribe_local.py podcast.wav --task translate --output-dir ./output

Available models (by size and accuracy):
  tiny    - ~39 MB,  ~32x realtime speed
  base    - ~74 MB,  ~16x realtime speed
  small   - ~244 MB, ~6x realtime speed
  medium  - ~769 MB, ~2x realtime speed
  large   - ~1550 MB, ~1x realtime speed
        """,
    )

    parser.add_argument("audio_file", help="Path to the audio/video file to transcribe")

    parser.add_argument(
        "--model",
        "-m",
        default="small",
        choices=["tiny", "base", "small", "medium", "large"],
        help="Whisper model size (default: small for better context)",
    )

    parser.add_argument("--language", "-l", default="en", help="Language code (default: en for English)")

    parser.add_argument(
        "--task",
        "-t",
        default="transcribe",
        choices=["transcribe", "translate"],
        help="Task to perform (default: transcribe)",
    )

    parser.add_argument(
        "--output-dir",
        "-o",
        help="Output directory for transcription files (default: same as input)",
    )

    parser.add_argument("--quiet", "-q", action="store_true", help="Suppress verbose output")

    args = parser.parse_args()

    try:
        result = transcribe_file(
            audio_path=args.audio_file,
            model_name=args.model,
            language=args.language,
            task=args.task,
            output_dir=args.output_dir,
            verbose=not args.quiet,
        )

        if not args.quiet:
            print("\nüéâ Transcription complete!")
            print(f"üìä Detected language: {result.get('language', 'unknown')}")
            print(f"üìù Text length: {len(result['text'])} characters")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
