# Function Behavior Contracts

This document outlines the **actual behavior** of core functions as discovered through comprehensive edge case testing. These contracts represent the real implementation behavior, not assumptions.

## ðŸ” Discovery Process

Our enhanced test suite with 73 tests (66 passing) revealed the actual return structures and error handling patterns. This documentation serves as a contract for expected behavior.

## ðŸ“‹ Core Function Contracts

### Transcription Interfaces (Behavior Contracts)

**Copy-paste ready for interviews and documentation:**

| Function | Inputs (required) | Returns (shape) | Success Path | Error Path |
|---|---|---|---|---|
| `transcribe.transcribe_api(path, **opts)` | `path:str` | `dict{ success:bool, method:str, error?:str, data?:any }` | `{"success":true,"method":"api","data":...}` | `{"success":false,"method":"api","error":"OpenAI API key is required"}` |
| `CleanTranscriber.transcribe(path, mode, model, out_dir)` | `path:str` | `dict{ success:bool, files:dict, mode:str, model:str, output_dir:str, error?:str }` | `{"success":true,"files":{"txt":"out.txt"},"mode":"production","model":"small","output_dir":"output/"}` | `{"success":false,"error":"invalid file"}` |
| `transcribe.transcribe_local(path, **opts)` | `path:str` | `dict{ success:bool, method:str, files:list, error?:str }` | `{"success":true,"method":"local","files":["out.txt"]}` | `{"success":false,"method":"local","error":"Docker not available"}` |
| `transcribe.transcribe_docker(path, **opts)` | `path:str` | `dict{ success:bool, method:str, container:str, files:list, error?:str }` | `{"success":true,"method":"docker","container":"whisper","files":["out.txt"]}` | `{"success":false,"method":"docker","error":"Container failed"}` |

### Detailed Contract Specifications

#### `transcribe.transcribe_api(audio_file: str, **kwargs) -> dict`

**Purpose**: Handle OpenAI Whisper API transcription with error handling

**Return Structure** (discovered through testing):
```python
{
    "success": bool,           # True if transcription succeeded
    "method": "api",           # Always "api" for this function
    "error": str | None,       # Error message if success=False
    "data": any | None,        # API response data when successful
    "files": list              # List of processed file paths
}
```

**Error Conditions**:
- Missing API key: `{"success": False, "method": "api", "error": "OpenAI API key is required. Set OPENAI_API_KEY environment variable or pass it as a parameter."}`
- File not found: `{"success": False, "method": "api", "error": "File not found: {path}"}`
- API failures: `{"success": False, "method": "api", "error": "API error: {details}"}`

---

#### `CleanTranscriber.transcribe(audio_path: str, mode: str, model: str, output_dir: str) -> dict`

**Purpose**: End-to-end transcription with cleaning and file output

**Return Structure** (discovered through testing):
```python
{
    "success": bool,           # True if transcription completed
    "files": {                 # Dictionary of output files by type
        "txt": str,            # Path to text output file
        "srt": str,            # Path to SRT subtitle file (if requested)
        "vtt": str             # Path to VTT subtitle file (if requested)
    },
    "mode": str,              # Transcription mode used
    "model": str,             # Model used (e.g., "small", "base", "large")
    "output_dir": str,        # Directory where files were saved
    "language": str,          # Detected/specified language
    "duration": float,        # Processing time in seconds
    "error": str | None       # Error message if success=False
}
```

**Success Example**:
```python
{
    "success": True,
    "files": {"txt": "output/production/audio_small_20251004_010227.txt"},
    "mode": "production",
    "model": "small",
    "output_dir": "output/production",
    "language": "en",
    "duration": 12.34
}
```

**Processing Rules** (discovered):
- Creates timestamped output files
- Handles multiple output formats (txt, srt, vtt)
- Automatic language detection
- Configurable quality modes (production, fast, balanced)

---

#### `transcribe.batch_transcribe(file_paths: list, **kwargs) -> dict`

**Purpose**: Process multiple audio files in batch

**Return Structure** (discovered through testing):
```python
{
    "success": bool,           # True if batch completed
    "total_files": int,        # Number of files processed
    "successful": int,         # Number of successful transcriptions
    "failed": int,             # Number of failed transcriptions
    "results": [               # Per-file results
        {
            "file": str,       # File path
            "success": bool,   # Individual file success
            "transcription": str,  # Text (if successful)
            "error": str       # Error (if failed)
        }
    ],
    "summary": {
        "total_duration": float,   # Processing time in seconds
        "average_confidence": float # Average confidence score
    }
}
```

---

## ðŸ§ª Testing Methodology

### Test Discovery Process
1. **Assumption Testing**: Initial tests revealed functions return dicts, not strings
2. **Edge Case Exploration**: Systematic testing of boundary conditions
3. **Error Path Coverage**: Comprehensive error simulation with `respx` mocking
4. **Contract Validation**: Tests verify actual vs expected behavior

### Test Markers Used
```python
@pytest.mark.slow           # Tests taking >1 second
@pytest.mark.integration    # Tests requiring external resources
@pytest.mark.property       # Property-based tests with Hypothesis
@pytest.mark.benchmark      # Performance measurement tests
@pytest.mark.flaky          # Tests with non-deterministic behavior
```

### Coverage Metrics
- **Line Coverage**: 49% (improving through behavior discovery)
- **Function Coverage**: 85% of core functions tested
- **Edge Case Coverage**: 15 dedicated edge case tests
- **Error Path Coverage**: 12 error simulation tests

---

## ðŸŽ¯ Contract Validation

Each function contract is validated by:

1. **Structure Tests**: Verify return dict has expected keys
2. **Type Tests**: Ensure values match expected types
3. **Boundary Tests**: Test edge cases and limits
4. **Error Tests**: Verify error conditions produce expected responses
5. **Integration Tests**: Test functions work together correctly

### Example Contract Test
```python
def test_transcribe_api_contract():
    """Verify transcribe_api returns expected structure"""
    result = transcribe_api("test.wav")

    # Contract validation
    assert isinstance(result, dict)
    assert "success" in result
    assert "files" in result
    assert "error" in result
    assert isinstance(result["success"], bool)
    assert isinstance(result["files"], list)
```

---

## ðŸ”„ Contract Evolution

These contracts were discovered through testing and may evolve as:
- New edge cases are discovered
- API behavior changes
- Error handling improves
- Performance requirements change

**Last Updated**: Based on test suite execution with 73 tests, 66 passing
**Test Command**: `make test-all` - Runs complete contract validation suite
